{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import bz2\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitReviewsLabels(lines):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for review in tqdm(lines):\n",
    "        rev = reviewToX(review)\n",
    "        label = reviewToY(review)\n",
    "        reviews.append(rev[:512])\n",
    "        labels.append(label)\n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviewToY(review):\n",
    "    return [1,0] if review.split(' ')[0] == '__label__1' else [0,1] \n",
    "\n",
    "def reviewToX(review):\n",
    "    review = review.split(' ', 1)[1][:-1].lower()\n",
    "    review = re.sub('\\d','0',review)\n",
    "    if 'www.' in review or 'http:' in review or 'https:' in review or '.com' in review:\n",
    "        review = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = bz2.BZ2File('./train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File('./test.ft.txt.bz2')\n",
    "\n",
    "train_lines = train_file.readlines()\n",
    "test_lines = test_file.readlines()\n",
    "\n",
    "train_lines = [x.decode('utf-8') for x in train_lines]\n",
    "test_lines = [x.decode('utf-8') for x in test_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 3600000/3600000 [00:53<00:00, 67903.99it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 400000/400000 [00:05<00:00, 67042.77it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load from the file\n",
    "reviews_train, y_train = splitReviewsLabels(train_lines)\n",
    "reviews_test, y_test = splitReviewsLabels(test_lines)\n",
    "\n",
    "reviews_train, y_train = shuffle(reviews_train, y_train)\n",
    "reviews_test, y_test = shuffle(reviews_test, y_test)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 8192\n",
    "maxlen = 128\n",
    "embed_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(reviews_train)\n",
    "\n",
    "token_train = tokenizer.texts_to_sequences(reviews_train)\n",
    "token_test = tokenizer.texts_to_sequences(reviews_test)\n",
    "\n",
    "x_train = pad_sequences(token_train, maxlen=maxlen, padding='post')\n",
    "x_test = pad_sequences(token_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0715 10:58:26.270829  3636 deprecation_wrapper.py:119] From c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0715 10:58:41.826187  3636 deprecation_wrapper.py:119] From c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0715 10:58:47.427420  3636 deprecation_wrapper.py:119] From c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0715 10:58:51.917491  3636 deprecation_wrapper.py:119] From c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0715 10:58:52.577296  3636 deprecation.py:506] From c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0715 10:58:56.572188  3636 deprecation_wrapper.py:119] From c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0715 10:58:56.707394  3636 deprecation_wrapper.py:119] From c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 128, 64)           524288    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128, 64)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 128, 32)           14368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 128, 32)           3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 128, 32)           3104      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128, 32)           128       \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 128, 32)           3104      \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 128, 2)            66        \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 548,674\n",
      "Trainable params: 548,354\n",
      "Non-trainable params: 320\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = Input(shape=(maxlen,))\n",
    "net = Embedding(max_features, embed_size)(input)\n",
    "net = Dropout(0.2)(net)\n",
    "net = BatchNormalization()(net)\n",
    "\n",
    "net = Conv1D(32, 7, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net1 = BatchNormalization()(net)\n",
    "\n",
    "net = Conv1D(2, 1)(net)\n",
    "net = GlobalAveragePooling1D()(net)\n",
    "output = Activation('softmax')(net)\n",
    "model = Model(inputs = input, outputs = output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0715 10:58:58.919482  3636 deprecation.py:323] From c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3240000 samples, validate on 360000 samples\n",
      "Epoch 1/5\n",
      " 110592/3240000 [>.............................] - ETA: 17:43:28 - loss: 0.7099 - acc: 0.491 - ETA: 9:40:10 - loss: 0.7014 - acc: 0.499 - ETA: 6:53:53 - loss: 0.6951 - acc: 0.52 - ETA: 5:29:18 - loss: 0.6928 - acc: 0.53 - ETA: 4:38:02 - loss: 0.6915 - acc: 0.53 - ETA: 4:03:29 - loss: 0.6893 - acc: 0.54 - ETA: 3:39:08 - loss: 0.6868 - acc: 0.54 - ETA: 3:21:14 - loss: 0.6839 - acc: 0.55 - ETA: 3:06:51 - loss: 0.6807 - acc: 0.56 - ETA: 2:55:20 - loss: 0.6772 - acc: 0.58 - ETA: 2:45:52 - loss: 0.6725 - acc: 0.59 - ETA: 2:38:00 - loss: 0.6679 - acc: 0.60 - ETA: 2:31:10 - loss: 0.6629 - acc: 0.61 - ETA: 2:25:24 - loss: 0.6567 - acc: 0.62 - ETA: 2:20:23 - loss: 0.6508 - acc: 0.63 - ETA: 2:15:57 - loss: 0.6434 - acc: 0.63 - ETA: 2:12:04 - loss: 0.6366 - acc: 0.64 - ETA: 2:08:37 - loss: 0.6295 - acc: 0.65 - ETA: 2:05:25 - loss: 0.6216 - acc: 0.66 - ETA: 2:02:36 - loss: 0.6132 - acc: 0.66 - ETA: 2:00:02 - loss: 0.6042 - acc: 0.67 - ETA: 1:57:43 - loss: 0.5962 - acc: 0.68 - ETA: 1:55:32 - loss: 0.5888 - acc: 0.68 - ETA: 1:53:36 - loss: 0.5810 - acc: 0.69 - ETA: 1:51:49 - loss: 0.5724 - acc: 0.70 - ETA: 1:50:12 - loss: 0.5646 - acc: 0.70 - ETA: 1:48:44 - loss: 0.5580 - acc: 0.71 - ETA: 1:47:22 - loss: 0.5511 - acc: 0.71 - ETA: 1:45:59 - loss: 0.5442 - acc: 0.72 - ETA: 1:44:43 - loss: 0.5379 - acc: 0.72 - ETA: 1:43:33 - loss: 0.5317 - acc: 0.72 - ETA: 1:42:26 - loss: 0.5264 - acc: 0.73 - ETA: 1:41:23 - loss: 0.5214 - acc: 0.73 - ETA: 1:40:23 - loss: 0.5168 - acc: 0.73 - ETA: 1:39:27 - loss: 0.5114 - acc: 0.74 - ETA: 1:38:34 - loss: 0.5069 - acc: 0.74 - ETA: 1:37:45 - loss: 0.5025 - acc: 0.74 - ETA: 1:37:08 - loss: 0.4970 - acc: 0.75 - ETA: 1:36:23 - loss: 0.4926 - acc: 0.75 - ETA: 1:35:40 - loss: 0.4890 - acc: 0.75 - ETA: 1:35:04 - loss: 0.4853 - acc: 0.76 - ETA: 1:34:24 - loss: 0.4819 - acc: 0.76 - ETA: 1:33:48 - loss: 0.4783 - acc: 0.76 - ETA: 1:33:12 - loss: 0.4746 - acc: 0.76 - ETA: 1:32:36 - loss: 0.4708 - acc: 0.77 - ETA: 1:32:05 - loss: 0.4673 - acc: 0.77 - ETA: 1:31:36 - loss: 0.4639 - acc: 0.77 - ETA: 1:31:07 - loss: 0.4608 - acc: 0.77 - ETA: 1:30:36 - loss: 0.4575 - acc: 0.77 - ETA: 1:30:08 - loss: 0.4548 - acc: 0.78 - ETA: 1:29:38 - loss: 0.4518 - acc: 0.78 - ETA: 1:29:20 - loss: 0.4486 - acc: 0.78 - ETA: 1:29:00 - loss: 0.4458 - acc: 0.78 - ETA: 1:28:36 - loss: 0.4430 - acc: 0.7880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0715 11:02:22.171533  3636 ultratb.py:155] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-5e422a6ae3e6>\", line 1, in <module>\n",
      "    model.fit(x_train, y_train, batch_size=2048, epochs=5, validation_split=0.1)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1039, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\", line 199, in fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2715, in __call__\n",
      "    return self._call(inputs)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 2675, in _call\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1458, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\0\\appdata\\local\\programs\\python\\python37\\lib\\inspect.py\", line 734, in getmodule\n",
      "    f = module.__file__\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=2048, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
